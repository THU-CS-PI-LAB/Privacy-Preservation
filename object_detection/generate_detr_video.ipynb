{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_raw = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "classes_modified = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# colors for visualization\n",
    "colors_raw = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pil_img, prob, boxes, name):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = colors_raw * 100\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   alpha=0.3, color=c, linewidth=3))\n",
    "        cl = p.argmax()\n",
    "        text = f'{classes_raw[cl]}: {p[cl]:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=30,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [15, 20, 30, 50, 100, 160, 240]\n",
    "plot_folder = './video_plot/'\n",
    "info_folder = './video_result/'\n",
    "for resolution in resolutions:\n",
    "    test_folder = './nearest/video_test_nearest_' + str(resolution)\n",
    "    if os.path.exists(os.path.join(plot_folder, str(resolution))):\n",
    "        shutil.rmtree(os.path.join(plot_folder, str(resolution)))\n",
    "    os.makedirs(os.path.join(plot_folder, str(resolution)))\n",
    "    if os.path.exists(os.path.join(info_folder, str(resolution))):\n",
    "        shutil.rmtree(os.path.join(info_folder, str(resolution)))\n",
    "    os.makedirs(os.path.join(info_folder, str(resolution)))\n",
    "    for video_folder in os.listdir(test_folder):\n",
    "        if video_folder == \".DS_Store\":\n",
    "            continue\n",
    "        for picture_name in os.listdir(os.path.join(test_folder, video_folder)):\n",
    "            if picture_name == \".DS_Store\":\n",
    "                continue\n",
    "            im = Image.open(os.path.join(test_folder, video_folder, picture_name))\n",
    "            img = transform(im).unsqueeze(0)\n",
    "            outputs = model(img)\n",
    "            probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "            keep = probas.max(-1).values > 0.7\n",
    "            bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
    "            info = {}\n",
    "            objects = []\n",
    "            plot_path = os.path.join(plot_folder, str(resolution), picture_name + '.jpg')\n",
    "            info_path = os.path.join(info_folder, str(resolution), picture_name + '.json')\n",
    "            plot_results(im, probas[keep], bboxes_scaled, plot_path)\n",
    "            for p, (xmin, ymin, xmax, ymax) in zip(probas[keep], bboxes_scaled.tolist()):\n",
    "                single_object = {}\n",
    "                single_object['points'] = [xmin, ymin, xmax, ymax]\n",
    "                single_object['score'] = p[p.argmax()].item()\n",
    "                single_object['label'] = classes_raw[p.argmax()]\n",
    "                objects.append(single_object)\n",
    "            info['objects'] = objects\n",
    "            with open(info_path, 'w', encoding='utf8') as objects_file:\n",
    "                json.dump(info, objects_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes2idx = {}\n",
    "for idx, classes in enumerate(classes_modified):\n",
    "    classes2idx[classes] = idx\n",
    "print(classes2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 15\n",
    "source_path = \"./data/\"\n",
    "dest_path = './objects/' + str(size)\n",
    "list_path = './list/' + str(size) + '/test.txt'\n",
    "if os.path.isdir(dest_path):\n",
    "    shutil.rmtree(dest_path)\n",
    "os.mkdir(dest_path)\n",
    "# if os.path.exists(list_path):\n",
    "#     os.remove(list_path)\n",
    "for folder in os.listdir(source_path):\n",
    "    if folder == \".DS_Store\":\n",
    "        continue\n",
    "    for picture in os.listdir(os.path.join(source_path, folder)):\n",
    "        if picture == \".DS_Store\":\n",
    "            continue\n",
    "        image = Image.open(os.path.join(source_path, folder, picture))\n",
    "        image = image.resize((size, size), Image.BICUBIC)\n",
    "        img = transform(image).unsqueeze(0)\n",
    "        outputs = model(img)\n",
    "        probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "        keep = probas.max(-1).values > 0.7\n",
    "        bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], image.size)\n",
    "        objects = {}\n",
    "        objects['bboxes'] = bboxes_scaled.tolist()\n",
    "        objects['categories'] = []\n",
    "        people = {}\n",
    "        probability = []\n",
    "        for prob in probas[keep]:\n",
    "            cl = prob.argmax()\n",
    "            probability.append(prob[cl])\n",
    "            objects['categories'].append(classes2idx[classes_raw[cl.item()]])\n",
    "        match_result = re.match(r'(\\d*)_(.*).jpg', picture)\n",
    "        index = match_result.group(1)\n",
    "        with open(os.path.join(dest_path, index + '.json'),'w',encoding='utf8') as objects_file:\n",
    "            json.dump(objects, objects_file, ensure_ascii=False)\n",
    "#         for prob, bbox, classes in zip(probability, objects['bboxes'], objects['categories']):\n",
    "#             if classes == 0:\n",
    "#                 people[prob.item()] = bbox\n",
    "#         people_sorted = sorted(people.items(), key=lambda x:x[0], reverse=True)\n",
    "#         if len(people_sorted) <= 1:\n",
    "#             continue\n",
    "#         person_pair = []\n",
    "#         for idx in range(0, len(people_sorted)):\n",
    "#             for jdx in range(idx + 1, len(people_sorted)):\n",
    "#                 person_pair.append([people_sorted[idx][1], people_sorted[jdx][1]])\n",
    "#         with open(list_path, 'a', encoding='utf8') as list_file:\n",
    "#             for ([[xmin1, ymin1, xmax1, ymax1], [xmin2, ymin2, xmax2, ymax2]]) in person_pair:\n",
    "#                 list_file.write(index + '.jpg ' + str((int)(xmin1)) + ' ' + str((int)(ymin1)) + ' ' + str((int)(xmax1)) + ' ' + str((int)(ymax1)) + ' '\n",
    "#                 + str((int)(xmin2)) + ' ' + str((int)(ymin2)) + ' ' + str((int)(xmax2)) + ' ' + str((int)(ymax2)) + ' ' + '0\\n') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de401cb0ebe5c3a98decf1b15e5a14f89ea85648ba9964f9d64ffd16b516b437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
